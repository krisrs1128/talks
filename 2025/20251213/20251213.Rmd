---
title: "Interactively Resolving Distortion in Nonlinear Dimensionality Reduction"
author: "Kris Sankaran"
output:
  xaringan::moon_reader:
    css: ["default", "css/xaringan-themer.css"]
    lib_dir: libs
    self_contained: false
    nature:
      highlightStyle: github
      highlightLines: true
      ratio: "16:9"
    seal: false
date: "`r Sys.Date()`"
---

class: title

# Interactively Resolving Distortion in Nonlinear Dimensionality Reduction

<style>
.slide-background {
    background: url("figures/cover.png") no-repeat center center;
    background-size: cover;
    opacity: 0.5;
}
</style>

<div id="subtitle_left">
Paper: <a href="https://go.wisc.edu/oe3g62"/>go.wisc.edu/oe3g62</a><br/>
Slides: <a href="https://go.wisc.edu/ozm0il">go.wisc.edu/ozm0il</a><br/>
Lab: <a href="https://measurement-and-microbes.org">measurement-and-microbes.org</a> <br/>
Joint w/
Shuzhen Zhang, Chenab, and Marina Meila <br/>
</div>
<div id="subtitle_right">
Kris Sankaran <br/>
CMStatistics <br/>
13 | December | 2025 <br/>
</div>

<!-- 25 minute talk -->

```{r, echo = FALSE, warning = FALSE}
library(knitr)
library(RefManageR)

opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, cache = FALSE, dpi = 200, fig.align = "center", fig.width = 6, fig.height = 3)
BibOptions(
  check.entries = FALSE,
  bib.style = "numeric",
  cite.style = "numeric",
  style = "markdown",
  hyperlink = FALSE,
  dashed = FALSE,
  max.names = 1
)
bib <- ReadBib("references.bib")
```

---

### Map Distortions

 When making maps, we know that any projection introduces some degree of
 distortion. It's impossible to map the 3D earth into a 2D map while preserving
 all metric properties.

.center[
<img src="figures/mercator-old.png" width=450/>
]

Gerardus Mercator's 1569 map of the world.

---

### Map Distortions

For example, the Mercator projection artificially inflates areas at the poles.
But it perfectly preserves angles, and this was extremely important for ocean
navigation.

.center[
<img src="figures/mercator.jpg" width=500/>
]

---

### High-Dimensional Distortions

The same is true for high-dimensional data. Despite the popularity of nonlinear
dimensionality reductions like UMAP and t-SNE, we know that they introduce
distortions. For example, they may not preserve density within different
regions of the plot.

.center[
<img src="figures/densmap_example.png" width=1000/>
]
Example from `r Citep(bib, "narayan2021assessing")`.

---

### High-Dimensional Distortions

They can make high-dimensional random walks look artificially smooth...

.center[<img src="figures/gaussian_rw.png" width=600/> ]
Example from `r Citep(bib, "wattenberg2016how")`.

---

### High-Dimensional Distortions

They can also fail to preserve the topology of the underlying data...

.center[
<img src="figures/tsne-initialization.png" width=600/>
]
Example from `r Citep(bib, "Kobak2021")`.

---

### Consequences

These distortions are not mere technical curiosities -- they can significantly
impact scientific interpretation `r Citep(bib, c("Liu2025", "Kobak2021"))`. For example, they have been known to create
misleading differences between cell types that are actually quite similar.

.center[
<img src="figures/scdeed-example.png" width=700/>
]
Example from `r Citep(bib, "xia2024statistical")`.

---

### Controversy

.pull-three-quarters-left[
<img src="figures/pritchard_all_of_us.png" width=600/>
]

.pull-three-quarters-right[
See also `r Citep(bib, c("simplystatisticsSimplyStatistics", "Kozlov2024"))`.
]

---

### Specious Art

More generally, nonlinear dimensionality reduction has become the source of
widespread concern in the single cell literature `r Citep(bib, "Chari2023")`.

.center[
<img src="figures/specious_art.png" width=700/>
]

---

### Approach

We shouldn't abandon nonlinear dimensionality reduction, but we should try to
characterize the distortion. Our idea is to augment our usual visualizations
with measures of local distortion which are already available in the literature.

.center[
<img src="figures/tissot-1.png" width=400/>
<img src="figures/tissot-2.png" width=400/>
]

This is similar in spirit to Tissot's indicatrix in the cartography literature
`r Citep(bib, "laskowski1989traditional")`.

---

.center[
## Implementation
]

---

### Graph-based Metrics

The graph Laplacian induces a metric in the original manifold. Intuitively, two
points are close to one another if a random walk started at one point has a high
probability ending up at the other after $t$ steps.

.center[
<img src="figures/random-walk-laplacian.svg" width=800/>
]

---

### Metric Distortion

The RMetric algorithm measures how these intrinsic, graph-based distances become
distorted during the embedding process `r Citep(bib, c("perrault2006metric", "mcqueen2016nearly"))`.
This geometric view has connections to `r Citep(bib, c("Venna2006", "xia2024statistical", "Ovchinnikova2020"))`.

---

### Local Metric Distortion

.center[
<img src="figures/rmetric_explanation-v2.png" width=710/>
]

---

### Implementation Details

Suppose that the $k^{th}$ dimension of the embedding algorithm is $z_{k} \in \mathbb{R}^{N}$.
It turns out that the diffusion metric in the original space is transformed in
the embedding space according to the local metrics:

\begin{align*}
H_{\cdot, kl} := \frac{1}{2}\left[L\left(z_{k} \circ z_{l}\right) - z_{k} \circ \left(L z_{l}\right) - z_{l} \circ \left(L z_{k}\right)  \right]
\end{align*}

.center[
<img src="figures/g_kl.png" width=350/>
]


---

### Example

These two clusters are generated as:

\begin{align*}
x_{i} \sim \frac{1}{2}\mathcal{N}\left(0, 10\right) + \frac{1}{2}\mathcal{N}\left(100, 1\right)
\end{align*}

.center[
<img src="figures/unequal_variances.png" width=700/>
]

---

### Example

The UMAP embeddings lose information about the cluster density, but the
difference is captured in the local metrics.

.center[
<img src="figures/unequal_variances_ellipse.png" width=700/>
]

---

### Local Isometrization

Since we know the metrics locally, we can invert the distortion within a
neighborhood of the cursor. For example, here we interactively adapt the
embeddings in the gaussian mixtures example.

.center[
<img src="figures/two_cluster_interaction.gif" width=600/>
]

---

### Embedding Discontinuities

.pull-left[
- RMetric works well when distortions are "smooth" and the graph Laplacian
reflects derivative information of the embedding map.

- It fails when their are discontinuities -- two points that are close to one
another in the original space but which are fragmented in the embedding.
]

.pull-right[
<img src="figures/distance_preservation.png" width=400/>
]

---

### Fragmented Neighborhoods

Some neighborhoods have poorly preserved distances. To detect this, one approach
is:

* Fit the running median in a scatterplot of true vs. embedding distances.
* Compute the IQR within each bin. Points above $3\times$ IQR are considered poorly preserved outliers.
* If a large enough fraction of a point's neighbor links are poorly preserved, then that point is flagged as "broken."

---

### Fragmented Neighborhoods

.center[
<img src="figures/bin-outlier-defin.png" width=1100/>
]

---

.center[
## Examples
]

---

This is the classic Swiss Roll data, but with higher density near the
endpoints.

<center>
```{r, echo = FALSE, out.width = 500, fig.align="center"}
library(tidyverse)
library(plotly)
library(scico)
library(grDevices)
library(scales)
sr <- read_csv("/Users/krissankaran/Desktop/collaborations/distortions-project/distortions/docs/tutorials/baselines/data/swiss_noise_0.5.csv") |>
  rename(x = `0`, y = `1`, z = `2`, t = `3`)

# map continuous `t` to the ggplot2-style gradient
rng <- range(sr$t, na.rm = TRUE)
t_scaled <- (sr$t - rng[1]) / diff(rng)
pal_fun <- colorRamp(c("#B776A6", "#BAC4A2"))
cols_mat <- matrix(NA_real_, nrow = length(t_scaled), ncol = 3)
cols_mat <- pal_fun(t_scaled)
sr$col <- rgb(cols_mat[,1], cols_mat[,2], cols_mat[,3], maxColorValue = 255)


p <- plot_ly(sr, x = ~x, y = ~y, z = ~z, type = 'scatter3d', mode = 'markers', marker = list(color = ~col, size = 4), hoverinfo = 'none', showlegend = FALSE) %>%
  layout(scene = list(
    xaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
    yaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE),
    zaxis = list(showgrid = FALSE, zeroline = FALSE, showticklabels = FALSE)
  )) %>%
  config(displayModeBar = FALSE)
p
```
</center>

---

### Variable Density Swiss Roll

$t$-SNE (perplexity = 100) breaks the roll in the low-density region. It also
artificially spreads out the high density area.

.center[
<img src="figures/noisy_embedding_0.5.png" width=640/>
]

---

### Fragmented Neighborhoods

.center[
<img src="figures/swiss_roll_neighborhoods.gif" width=640/>
]

---

### Poorly Preserved Distances

.center[
<img src="figures/swiss_roll_boxplot.gif" width=710/>
]

---

### Comparison with LOO-map

The stability-based algorithm `r Citep(bib, "Liu2025")` gives a similar
interpretation. But the visual encoding is more subtle, and the leave-one-out
approach is time consuming even with approximations.

.center[
<img src="figures/p_scores_0.5.png" width=600/>
]

---

### Mammoth

This example comes from `r Citep(bib, c("paircodeUnderstandingUMAP", "maxnoichlNoichlFlattening"))`. The 3D skeleton scans were produced by the
Smithsonian, and we can use nonlinear dimensionality reduction to "flatten" the
skeleton into 2D.

.center[
<img src="figures/mammoth_truth.gif" width=600/>
]

---

### Mammoth

This is the embedding when applying UMAP with a 50 nearest neighbor graph and
`min_dist = 0.5`.

.center[
<img src="figures/mammoth_plain_umap.png" width=500/>
]

---

### Mammoth

Parts of the shoulders, head, and tail are further apart in the embedding
compared to the original data. Most of other distortions are points that are
placed too close to one another.

.center[
<img src="figures/mammoth_neighborhoods.gif" width=450/>
]

---

### Mammoth

Parts of the shoulders, head, and tail are further apart in the embedding
compared to the original data. Most of other distortions are points that are
placed too close to one another.

.center[
<img src="figures/mammoth_boxplot_inter.gif" width=550/>
]

---

### PBMC Dataset

This single cell gene expression data set used in the introductory data
visualization tutorial from the scanpy package `r Citep(bib, "scanpytutorialsAnalysisVisualization")`. Each point is the UMAP embedding of a
cell's high-dimensional gene expression data.

.center[
<img src="figures/pbmc-a.png" width=490/>
]

---

### PBMC Dataset

* Distance scales vary both across and within clusters.
* There are two sets of T-cells that are closer to Monocytes than the embedding alone suggests.

.center[
<img src="figures/pbmc_boxplot_inter.gif" width=570/>
]

---

### Hydra Cell Atlas

.pull-left[
Here is an application to a hydra cell differentiation dataset `r Citep(bib, c("Siebert2019", "xia2024statistical"))`. We fit t-SNE with the perplexity hyperparameter set to 80. Points around the boundary are collapsed, and between-cluster distances are
exaggerated.
]

.pull-right[
<img src="figures/hydra_perplexity_80.gif" width=470/>
]

---

### Hydra Cell Atlas

.pull-left[
Increasing perplexity to 500, the clusters are more reliable, but samples along
the boundary of the visualization are in fact closer than they appear.
]

.pull-right[
<img src="figures/hydra_perplexity_500.gif" width=470/>
]

---

### Hydra Cell Atlas

.pull-left[
Applying the local isometry visualization, we can see that some of the "threads"
are actually more spread out in the original data.
]

.pull-right[
<img src="figures/hydra_isometry.gif" width=470/>
]

---

### DensMap vs. UMAP

Both variation in ellipses and fragmented neighborhood statistics can be used to
compare competing algorithms, similarly to `r Citep(bib, c("xia2024statistical", "Venna2006"))`.

.center[
<img src="figures/densmap_v_umap.png" width=900/>
]

This example uses data from a _C. elegans_ cell differentiation study `r Citep(bib, "Packer2019")`.

---

### DensMap vs. UMAP

Both variation in ellipses and fragmented neighborhood statistics can be used to
compare competing algorithms, similarly to `r Citep(bib, c("xia2024statistical", "Venna2006"))`.

.center[
<img src="figures/densmap_v_umap_hist.png" width=950/>
]

This example uses data from a _C. elegans_ cell differentiation study `r Citep(bib, "Packer2019")`.

---

### Summary

1. Distortion in nonlinear dimensionality reduction may be inevitable, but there
are ways to systematically characterize it.

1. Interactivity makes it possible to progressively reveal extra information
related to distortion depending on the analysts' priorities.

**Paper**: https://go.wisc.edu/oe3g62<br/>

**Package**:
- https://github.com/krisrs1128/distortions
- https://pypi.org/project/distortions

.center[
```{python, eval = FALSE, echo = TRUE}
pip install distortions
```
]
---

### Thank you!

* Contact: ksankaran@wisc.edu
* Lab Members: Margaret Thairu, Yuliang Peng, Langtian Ma, Cameron Jones, Jiaxin Ye, Megan Kuo, Helena Huang
* Funding: NIGMS R01GM152744, NIAID R01AI184095

---

class: reference

### References

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 1, end = 13)
```

---

class: reference

### References

```{r, results='asis', echo = FALSE}
PrintBibliography(bib, start = 14, end = 28)
```

---

### Graph Laplacian

This random walk information is encoded in the normalized graph laplacian.

.pull-left[
\begin{align}
K_{nn'} &= \text{exp}\left(-\frac{1}{\epsilon}\|x_{n} - x_{n'}\|^2\right)\\
D &= \text{diag}\left(K \mathbf{1}_{N}\right)\\
\tilde{K} &= D^{-1}K D^{-1}
\end{align}
]

.pull-right[
\begin{align}
\tilde{D} &= \text{diag}\left(K \mathbf{1}_{N}\right) \\
L &= \frac{1}{\epsilon}\left[I - \tilde{D}^{-1}\tilde{K}\right] \\
\end{align}
]

---

### PBMC Dataset

* Distance scales vary both across and within clusters.
* There are two sets of T-cells that are closer to Monocytes than the embedding alone suggests.

.center[
<img src="figures/pbmc_neighborhoods.gif" width=500/>
]